# IUSTDeepLearningWithTensorFlow
Deep Learning with TensorFlow Course at Iran University of Science and Technology

## Resources
|Week|Slides|Links|Repositories|Screen Captures|
|:--:|:----:|:---:|:----------:|:-------------:|
|1|[Introduction to Deep Learning with TensorFlow](https://www.dropbox.com/s/m14iaynhl7coqfa/Introduction%20to%20Deep%20Learning%20with%20TensorFlow.pdf?dl=1)<br>[CS231n 2017 Lecture4 Selected](https://www.dropbox.com/s/zs8iw941t5mkw4n/cs231n_2017_lecture4_selected.pdf?dl=1)<br>[CS224n 2017 TensorFlow Selected](https://www.dropbox.com/s/rua09j7gxsygigp/cs224n-2017-tensorflow-selected.pdf?dl=1)<br>[TensorFlow and Deep Learning without a Phd](https://www.dropbox.com/s/20o91shh8r6ow9a/Tensorflow%20and%20Deep%20Learning%20-%20Slides_0.pdf?dl=1) | [Tutorial - Learn Python in 10 minutes](https://www.stavros.io/tutorials/python/)<br>[Python Numpy Tutorial](http://cs231n.github.io/python-numpy-tutorial/)<br>[Machine Learning is Fun!](https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471)<br>[A Gentle Guide to Machine Learning](https://monkeylearn.com/blog/gentle-guide-to-machine-learning/)<br>[An Overview of Gradient Descent Optimization Algorithms](http://ruder.io/optimizing-gradient-descent/)<br>[Visualising Activation Functions in Neural Networks](https://dashee87.github.io/data%20science/deep%20learning/visualising-activation-functions-in-neural-networks/)<br>[My Neural Network isn't working! What should I do?](http://theorangeduck.com/page/neural-network-not-working)<br>[Learn TensorFlow and deep learning, without a Ph.D.](https://cloud.google.com/blog/big-data/2017/01/learn-tensorflow-and-deep-learning-without-a-phd) | [TensorFlow-Examples](https://github.com/aymericdamien/TensorFlow-Examples)<br>[Awesome-Tensorflow](https://github.com/jtoy/awesome-tensorflow)|[Week1.zip](http://deepnn.ir/mahdizade/Week1.zip)|
|2|[Introduction to Convolutional Neural Networks with TensorFlow](https://www.dropbox.com/s/n0ei09pzgpwimsc/Introduction%20to%20Convolutional%20Neural%20Networks%20with%20TensorFlow.pdf?dl=1)<br>[CS231n 2017 Lecture5 Selected](https://www.dropbox.com/s/qvw200ac00bu9fj/cs231n_2017_lecture5_selected.pdf?dl=1)|[A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks)<br>[A Guide to Convolution Arithmetic for DeepLearning](https://arxiv.org/pdf/1603.07285.pdf)|[Convolution Arithmetic](https://github.com/vdumoulin/conv_arithmetic)|[Week2.zip](http://deepnn.ir/mahdizade/Week2.zip)|
|3|[Introduction to Recurrent Neural Networks with TensorFlow](https://www.dropbox.com/s/u4xdeke79uhfbk4/Introduction%20to%20Recurrent%20Neural%20Networks%20with%20TensorFlow.pdf?dl=1)<br>[CS231n 2017 Lecture10 Selected](https://www.dropbox.com/s/v7hqpfcx61h0mtr/cs231n_2017_lecture10_selected.pdf?dl=1)<br>[Introduction to Deep NLP](https://prezi.com/ztuugu7fwtjo/introduction-to-deep-nlp/?utm_campaign=share&utm_medium=copy)<br>[TensorBoard](https://www.dropbox.com/s/k158hlaz5bke9gd/TensorBoard.pdf?dl=1)|[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)<br>[Sequence Modeling With Neural Networks (Part 1)](https://indico.io/blog/sequence-modeling-neuralnets-part1/)<br>[Sequence Modeling with Neural Networks (Part 2)](https://indico.io/blog/sequence-modeling-neural-networks-part2-attention-models/)<br>[Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)<br>[Attention and Memory in Deep Learning and NLP](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/)|[tensorflow-rnn-shakespeare](https://github.com/martin-gorner/tensorflow-rnn-shakespeare)|[Week3.zip](http://deepnn.ir/mahdizade/Week3.zip)|
|4|[Introduction to Word2Vec with Gensim and Hazm](https://www.dropbox.com/s/p1f8lkzkksy5q3n/Introduction%20to%20Word2Vec%20with%20Gensim%20and%20Hazm.pdf?dl=1)<br>[Introduction to Seq2Seq Models with TensorFlow](https://www.dropbox.com/s/8xkz1qft7ftroe5/Introduction%20to%20Seq2Seq%20Models%20with%20TensorFlow.pdf?dl=1)|[Persian Word2Vec Map](https://www.dropbox.com/s/afklflkj6uer1bg/words.jpg?dl=1)<br>[Word2Vec Resources](http://mccormickml.com/2016/04/27/word2vec-resources/)<br>[Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)<br>[Word2Vec Tutorial Part 2 - Negative Sampling](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/)<br>[On word embeddings - Part 1](http://ruder.io/word-embeddings-1/)<br>[Language Models, Word2Vec, and Efficient Softmax Approximations](http://rohanvarma.me/Word2Vec/)<br>[Deep learning with word2vec and gensim](https://rare-technologies.com/deep-learning-with-word2vec-and-gensim/)<br>[Word2vec Tutorial](https://rare-technologies.com/word2vec-tutorial/)<br>[Gensim Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html)<br>[Word2Vec word embedding tutorial in Python and TensorFlow](http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/)<br>[Sequence to sequence model: Introduction and concepts](https://towardsdatascience.com/sequence-to-sequence-model-introduction-and-concepts-44d9b41cd42d)|[Sequence to Sequence Learning with Keras](https://github.com/farizrahman4u/seq2seq)<br>[Dynamic seq2seq in TensorFlow, step by step](https://github.com/ematvey/tensorflow-seq2seq-tutorials)<br>[Chatbot](https://github.com/chiphuyen/stanford-tensorflow-tutorials/tree/master/assignments/chatbot)<br>[TensorFlow Neural Machine Translation Tutorial](https://github.com/tensorflow/nmt)|[Week4.zip](http://deepnn.ir/mahdizade/Week4.zip)|
|5|[Speech Related Task with DL](https://www.dropbox.com/s/14mem52e3uapnuu/Speech%20Related%20Task%20with%20DL.pdf?dl=1)|[WaveNet launches in the Google Assistant](https://deepmind.com/blog/wavenet-launches-google-assistant/)<br>[Deep Learning for Speech Recognition - Vikrant Singh Tomar](https://www.slideshare.net/LearnWTB/deep-learning-for-speech-recognition-vikrant-singh-tomar)<br>[Speech Recognition and Synthesis](https://nlp.stanford.edu/courses/lsa352/lsa352.lec7.ppt)|[Python Speech Features](https://github.com/jameslyons/python_speech_features)<br>[HTK Features Explained](https://github.com/danijel3/PyHTK/blob/master/python-notebooks/HTKFeaturesExplained.ipynb)<br>[Faster RNNLM](https://github.com/yandex/faster-rnnlm)<br>[warp CTC](https://github.com/baidu-research/warp-ctc)<br>[CTC + Tensorflow Example for ASR](https://github.com/igormq/ctc_tensorflow_example)|[Week5.zip](http://deepnn.ir/mahdizade/Week5.zip)|
|6|||||

## Codes

### [Week2](Codes/Week2/)
### [Week3](Codes/Week3/)
### [Week4](Codes/Week4/)
### [Week5](https://github.com/igormq/ctc_tensorflow_example/blob/master/ctc_tensorflow_example.py)